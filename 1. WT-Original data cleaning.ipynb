{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import r2_score\n",
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/t.wang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:38: FutureWarning: Creating a DatetimeIndex by passing range endpoints is deprecated.  Use `pandas.date_range` instead.\n",
      "/Users/t.wang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:48: FutureWarning: Creating a DatetimeIndex by passing range endpoints is deprecated.  Use `pandas.date_range` instead.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3    4    5    6    7    8    9   ...   25   26   27  \\\n",
      "0     1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "1     0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2     0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3     0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "4     0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "5     0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6     0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "7     0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "8     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
      "9     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
      "10    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "11    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "12    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "13    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "14    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "15    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "16    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "17    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "18    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "19    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "20    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "21    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "22    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "23    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "24    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "25    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "26    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "27    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "28    0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "29    0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "6546  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
      "6547  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
      "6548  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
      "6549  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
      "6550  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
      "6551  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
      "6552  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6553  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6554  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6555  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6556  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6557  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6558  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6559  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6560  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
      "6561  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
      "6562  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6563  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6564  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6565  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6566  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6567  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6568  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6569  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6570  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6571  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6572  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6573  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6574  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "6575  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "\n",
      "       28   29   30   31    32    33      0   \n",
      "0     0.0  0.0  1.0  2.0   3.0  70.0  142.25  \n",
      "1     0.0  0.0  1.0  2.0   3.0  65.0  143.00  \n",
      "2     0.0  0.0  1.0  2.0   3.0  65.0  160.00  \n",
      "3     0.0  0.0  1.0  2.0   2.0  65.0  166.00  \n",
      "4     0.0  0.0  1.0  2.0   1.0  65.0  142.50  \n",
      "5     0.0  0.0  1.0  2.0  -1.0  75.0  139.75  \n",
      "6     0.0  0.0  1.0  2.0  -1.0  75.0  141.50  \n",
      "7     0.0  0.0  1.0  2.0  -1.0  75.0  141.75  \n",
      "8     0.0  0.0  1.0  2.0  -1.0  75.0  139.25  \n",
      "9     0.0  0.0  1.0  2.0   0.0  75.0  143.50  \n",
      "10    0.0  0.0  1.0  2.0   2.0  60.0  140.50  \n",
      "11    0.0  0.0  1.0  2.0   4.0  39.0  141.50  \n",
      "12    0.0  0.0  1.0  2.0   6.0  29.0  144.25  \n",
      "13    0.0  0.0  1.0  2.0   6.0  31.0  140.50  \n",
      "14    0.0  0.0  1.0  2.0   6.0  29.0  144.25  \n",
      "15    0.0  0.0  1.0  2.0   6.0  29.0  139.25  \n",
      "16    0.0  0.0  1.0  2.0   5.0  29.0  139.75  \n",
      "17    0.0  0.0  1.0  2.0   3.0  33.0  200.50  \n",
      "18    0.0  0.0  1.0  2.0   1.0  41.0  218.50  \n",
      "19    0.0  0.0  1.0  2.0  -1.0  44.0  224.00  \n",
      "20    0.0  0.0  1.0  2.0  -2.0  43.0  217.25  \n",
      "21    0.0  0.0  1.0  2.0  -3.0  47.0  221.75  \n",
      "22    0.0  0.0  1.0  2.0  -4.0  50.0  221.25  \n",
      "23    0.0  0.0  1.0  2.0  -3.0  47.0  219.75  \n",
      "24    0.0  0.0  0.0  2.0  -3.0  47.0  221.50  \n",
      "25    0.0  0.0  0.0  2.0  -4.0  50.0  220.50  \n",
      "26    0.0  0.0  0.0  2.0  -5.0  54.0  220.00  \n",
      "27    0.0  0.0  0.0  2.0  -6.0  58.0  213.00  \n",
      "28    0.0  0.0  0.0  2.0  -7.0  63.0  219.50  \n",
      "29    0.0  0.0  0.0  2.0  -8.0  68.0  215.50  \n",
      "...   ...  ...  ...  ...   ...   ...     ...  \n",
      "6546  0.0  0.0  0.0  1.0   7.3  60.0  269.25  \n",
      "6547  0.0  0.0  0.0  1.0   6.9  63.0  275.50  \n",
      "6548  0.0  0.0  0.0  1.0   7.0  68.0  284.00  \n",
      "6549  0.0  0.0  0.0  1.0   3.3  80.0  282.50  \n",
      "6550  0.0  0.0  0.0  1.0   1.8  87.0  291.50  \n",
      "6551  0.0  0.0  0.0  1.0   3.9  75.0  280.75  \n",
      "6552  1.0  0.0  0.0  1.0   3.7  74.0  277.25  \n",
      "6553  1.0  0.0  0.0  1.0   2.2  77.0  264.75  \n",
      "6554  1.0  0.0  0.0  1.0   0.8  79.0  211.00  \n",
      "6555  1.0  0.0  0.0  1.0   1.2  78.0  182.00  \n",
      "6556  1.0  0.0  0.0  1.0   0.9  79.0  172.50  \n",
      "6557  1.0  0.0  0.0  1.0   1.2  78.0  162.00  \n",
      "6558  1.0  0.0  0.0  1.0   0.6  79.0  162.75  \n",
      "6559  1.0  0.0  0.0  1.0   0.0  82.0  169.00  \n",
      "6560  1.0  0.0  0.0  1.0   0.0  80.0  158.00  \n",
      "6561  1.0  0.0  0.0  1.0   2.0  76.0  146.50  \n",
      "6562  1.0  0.0  0.0  1.0   4.5  68.0  148.00  \n",
      "6563  1.0  0.0  0.0  1.0   6.3  62.0  149.25  \n",
      "6564  1.0  0.0  0.0  1.0   7.4  58.0  144.00  \n",
      "6565  1.0  0.0  0.0  1.0   8.7  53.0  146.25  \n",
      "6566  1.0  0.0  0.0  1.0  10.1  49.0  145.75  \n",
      "6567  1.0  0.0  0.0  1.0  11.0  47.0  170.25  \n",
      "6568  1.0  0.0  0.0  1.0  10.5  48.0  226.00  \n",
      "6569  1.0  0.0  0.0  1.0   4.9  65.0  243.50  \n",
      "6570  1.0  0.0  0.0  1.0   3.0  74.0  262.75  \n",
      "6571  1.0  0.0  0.0  1.0   1.1  82.0  267.00  \n",
      "6572  1.0  0.0  0.0  1.0   3.9  76.0  266.75  \n",
      "6573  1.0  0.0  0.0  1.0   2.9  80.0  276.75  \n",
      "6574  1.0  0.0  0.0  1.0   1.3  87.0  272.25  \n",
      "6575  1.0  0.0  0.0  1.0   2.5  86.0  264.25  \n",
      "\n",
      "[6576 rows x 35 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4983030361099856"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read meta data\n",
    "meta = pd.read_csv('/Users/t.wang/Desktop/Dissertation/Python/input/meta_open.csv', \n",
    "                   index_col='uid', parse_dates=['dataend','datastart'], dayfirst=True)#The data will be messed up withou specifying dayfirst\n",
    "\n",
    "\n",
    "# Read energy data\n",
    "temporal = pd.read_csv('/Users/t.wang/Desktop/Dissertation/Python/input/temp_open_utc_complete.csv', \n",
    "                   index_col='timestamp', parse_dates=True)#.tz_localize('utc')\n",
    "\n",
    "# Read energy data for each given buildingname\n",
    "single_building = 'Office_Benthe'\n",
    "single_timezone = meta.T[single_building].timezone\n",
    "startdate = meta.T[single_building].datastart\n",
    "enddate = meta.T[single_building].dataend\n",
    "single_building_energy = temporal[single_building].tz_convert(single_timezone).truncate(before = startdate, \n",
    "                                                            after = enddate)#.fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "# single_building_energy = single_building_energy.dropna()\n",
    "# print(startdate)\n",
    "# print(single_building_energy)\n",
    "# single_building_energy, some nan data\n",
    "\n",
    "\n",
    "# Get weather data for given building\n",
    "weatherfile_name = meta.T[single_building].newweatherfilename\n",
    "weather_data = pd.read_csv(os.path.join('/Users/t.wang/Desktop/Dissertation/Python/input/',\n",
    "                                        weatherfile_name),index_col='timestamp', parse_dates=True, na_values='-9999')\n",
    "weather_data = weather_data.tz_localize(single_timezone, ambiguous = 'infer')\n",
    "weather_point = ['TemperatureC', 'Humidity'] #Whatever weather features you want, put in the list\n",
    "weather_point_list=[]\n",
    "for point in weather_point:\n",
    "    point_data = weather_data[[point]]\n",
    "    weather_point_list.append(point_data)\n",
    "    all_weather_point = pd.concat(weather_point_list,axis=1) #axis=1, rowwise concat\n",
    "    all_weather_point = all_weather_point[~all_weather_point.index.duplicated()]#To get rid of duplicated index\n",
    "    all_weather_point = all_weather_point.reindex(pd.DatetimeIndex(start = all_weather_point.index[0], \n",
    "                                                                   periods=len(single_building_energy), \n",
    "                                                                   freq='H')).fillna(method='ffill').fillna(method='bfill')\n",
    "# print(single_building_energy.shape, all_weather_point.shape)\n",
    "    \n",
    "# Get schedule data for given building\n",
    "schedule_name = meta.T[single_building].annualschedule\n",
    "schedule_data = pd.read_csv(os.path.join('/Users/t.wang/Desktop/Dissertation/Python/input/',\n",
    "                                        schedule_name),index_col=0, header=None, parse_dates=True)\n",
    "schedule_data = schedule_data.tz_localize(single_timezone, ambiguous = 'infer')\n",
    "schedule_data.columns = ['seasonal']\n",
    "schedule_data = schedule_data.reindex(pd.DatetimeIndex(start = schedule_data.index[0], periods=len(single_building_energy), \n",
    "                                                       freq='H')).fillna(method='ffill').fillna(method='bfill')\n",
    "# print(schedule_data.shape)\n",
    "\n",
    "# Create TimeSeriesSplit\n",
    "# get the month number for splitting\n",
    "months = np.array(single_building_energy.index.month.unique())\n",
    "n_splits = 3\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "train_test_list = []\n",
    "for train_index, test_index in tscv.split(months):\n",
    "    months_train, months_test = months[train_index], months[test_index]\n",
    "    train_test_list.append([months_train, months_test])\n",
    "# Add the 'every-four-month' version, 5th month is duplicated in Clayton's notebook\n",
    "train_test_list.append([np.concatenate([months[0:3],months[4:7],months[8:11]]),\n",
    "                                     np.array([months[3],months[7],months[11]])])\n",
    "for train_index, test_index in train_test_list: #get rid of the 'array', extract the numeric months from the list\n",
    "#     print(train_index, test_index)\n",
    "    months_for_train = train_index\n",
    "    months_for_test = test_index\n",
    "# print(months_for_train,months_for_test)\n",
    "    \n",
    "# Create features and labels, this example did not loop but just for one TimeSeriesSplit, 9monthsTrain and 3monthsTest\n",
    "def get_features_and_labels(train_or_test):\n",
    "    global single_building_energy\n",
    "    global all_weather_point\n",
    "    global schedule_data\n",
    "    single_building_energy_n = single_building_energy[single_building_energy.index.month.isin(train_or_test)]\n",
    "#     single_building_energy_n.to_csv('/Users/t.wang/Desktop/' + 'single_building_energy_n' +'.csv', index=True)\n",
    "    \n",
    "    all_weather_point_n = all_weather_point[all_weather_point.index.month.isin(train_or_test)]\n",
    "#     all_weather_point_n.to_csv('/Users/t.wang/Desktop/' + 'all_weather_point_n' +'.csv', index=True)\n",
    "    \n",
    "    schedule_data_n = schedule_data[schedule_data.index.month.isin(train_or_test)]\n",
    "#     schedule_data_n.to_csv('/Users/t.wang/Desktop/' + 'schedule_data_n' +'.csv', index=True)\n",
    "    \n",
    "#     print(single_building_energy_n.shape, all_weather_point_n.shape, schedule_data_n.shape)\n",
    "    #rename _n is required, otherwise the function will run on top of incomplete dataset after one running(after traindata, testdata disappeared)\n",
    "    features = pd.merge(pd.get_dummies(single_building_energy_n.index.hour),\n",
    "                         pd.get_dummies(single_building_energy_n.index.dayofweek), right_index=True, left_index=True)\n",
    "#     features = pd.merge(features, pd.get_dummies(schedule_data_n.reset_index(drop=True)), right_index=True, left_index=True)\n",
    "    features = pd.merge(features, schedule_data_n.reset_index(drop=True), right_index=True, left_index=True)\n",
    "    features['seasonal_num'] = features.seasonal.map({'Break':0, 'Regular':1, 'Holiday':2, 'Summer':3})\n",
    "    features = features.drop('seasonal', axis=1)\n",
    "#     instead of get dummies in schedule data, map all strings to numbers helps to solve the inconsistency of schedules\n",
    "#     may result in information loss\n",
    "    features = pd.concat([features, all_weather_point_n.reset_index(drop=True)], axis=1) #.reset_index(drop=True) to get rid of the time index, otherwise two sets data will stratify\n",
    "    features = features.fillna(method='ffill').fillna(method='bfill')\n",
    "    features = np.array(features)\n",
    "    labels = single_building_energy_n.values\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "# test on model and calculate errors\n",
    "X_train, y_train = get_features_and_labels(train_or_test=months_for_train)\n",
    "compare = pd.concat([pd.DataFrame(X_train), pd.DataFrame(y_train)], axis=1)\n",
    "print(compare)\n",
    "X_test, y_test = get_features_and_labels(train_or_test=months_for_test)\n",
    "# print(y_test)\n",
    "random_forest = RandomForestRegressor(n_estimators=100, random_state=42, verbose=True)\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest.score(X_test, y_test)\n",
    "# predictions = random_forest.predict(X_test)\n",
    "# # print(predictions)\n",
    "# errors = abs(predictions - y_test)\n",
    "# MAPE = 100 * np.mean((errors / y_test))\n",
    "# NMBE = 100 * (sum(y_test - predictions) / (pd.Series(y_test).count() * np.mean(y_test)))\n",
    "# CVRSME = 100 * ((sum((y_test - predictions)**2) / (pd.Series(y_test).count()-1))**(0.5)) / np.mean(y_test)\n",
    "# RSQUARED = r2_score(y_test, predictions)\n",
    "# temporary = pd.DataFrame(columns=['building_name','MAPE','NMBE','CVRSME','RSQUARED'])\n",
    "# temporary.to_csv('/Users/t.wang/Desktop/Dissertation/Python/WT-result/' + 'test' +'.csv', index=False)\n",
    "# metrics_prev = pd.read_csv('/Users/t.wang/Desktop/Dissertation/Python/WT-result/' + 'test' +'.csv')\n",
    "# df = pd.DataFrame([[single_building, MAPE, NMBE, CVRSME, RSQUARED]],\n",
    "#                   columns=['building_name','MAPE','NMBE','CVRSME','RSQUARED'])\n",
    "# metrics = pd.concat([df, metrics_prev])\n",
    "# metrics.to_csv('/Users/t.wang/Desktop/Dissertation/Python/WT-result/' + 'test' +'.csv', index=False)\n",
    "\n",
    "\n",
    "# all_weather_point\n",
    "# schedule_data\n",
    "# single_building_energy\n",
    "# train_test_list\n",
    "# X_train,y_train\n",
    "# X_train.shape,y_train.shape\n",
    "# X_test,y_test\n",
    "# X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
